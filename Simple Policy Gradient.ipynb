{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Policy Gradient.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "N6DmPO15CELr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Policy Gradient\n",
        "\n",
        "This notebook contains the implementation of the Simple Policy Gradient Algorithm using TensorFlow.\n",
        "<br/>\n",
        "This notebook is created while going through the official Spinning up in Deep RL Docs."
      ]
    },
    {
      "metadata": {
        "id": "wr_BaDfxCwqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Required modules\n",
        "!pip install gym\n",
        "!apt-get install python-opengl\n",
        "!pip install pyglet==1.2.4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZhpqk-EN2oR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "from gym.spaces import Discrete, Box\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smhZs1BLOBkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "env_name = 'CartPole-v0'\n",
        "render = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l01SIfVNOO3c",
        "colab_type": "code",
        "outputId": "d0b2d823-78c3-4711-c3c9-02f06b898be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the env\n",
        "env = gym.make('CartPole-v0')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zh-CKSfDOUYC",
        "colab_type": "code",
        "outputId": "8710c29a-3bce-418e-b15d-9075f48fb689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the action space size and observation space size\n",
        "act_size = env.action_space.n\n",
        "obs_size = env.observation_space.shape[0]\n",
        "\n",
        "print ('Action Space Size: {}'.format(act_size),\n",
        "       '\\nObservation Space Size: {}'.format(obs_size))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Space Size: 2 \n",
            "Observation Space Size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rxr8GqXeRR8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network Hyperparameters\n",
        "layers = 2\n",
        "hneurons = [32, act_size]\n",
        "epochs = 50\n",
        "batch_size = 5000\n",
        "lr = 1e-2\n",
        "hid_act = tf.tanh\n",
        "out_act = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzCocISRRUSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build the network\n",
        "obs_ph = tf.placeholder(shape=(None, obs_size), dtype=tf.float32, name='input')\n",
        "\n",
        "a1 = tf.layers.dense(obs_ph, units=hneurons[0], activation=hid_act)\n",
        "logits = tf.layers.dense(a1, units=hneurons[1], activation=None)\n",
        "\n",
        "# Select the action\n",
        "actions = tf.squeeze(tf.multinomial(logits=logits, num_samples=1), axis=1)\n",
        "\n",
        "# Loss function whose gradient is the policy gradient\n",
        "weights_ph = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
        "act_ph = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
        "action_masks = tf.one_hot(act_ph, act_size)\n",
        "log_probs = tf.reduce_sum(action_masks * tf.nn.log_softmax(logits), axis=1)\n",
        "loss = -tf.reduce_mean(weights_ph * log_probs)\n",
        "\n",
        "# Make the train op\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pz-PkV1QNuz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgQJaVxnlYyv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_state(env):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    a = env.render(mode='rgb_array')\n",
        "    print (type(a))\n",
        "    print (a)\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cqq2GQRKL3HC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_one_epoch():\n",
        "    # Declaring variables to store epoch details\n",
        "    batch_acts = []\n",
        "    batch_len = []\n",
        "    batch_weights = []\n",
        "    batch_rews = []\n",
        "    batch_obs = []\n",
        "    \n",
        "    # Reset env\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    ep_rews = []\n",
        "    rendered_once_in_epoch = False\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        if not rendered_once_in_epoch:\n",
        "            # For notebooks on server (like Colab)\n",
        "            #show_state(env)\n",
        "            # For notebooks on local machines\n",
        "            #env.render()\n",
        "            pass\n",
        "            \n",
        "        batch_obs.append(obs)\n",
        "        \n",
        "        act = sess.run([actions], feed_dict={obs_ph: obs.reshape(1 ,-1)})[0][0]\n",
        "        \n",
        "        # Take the action\n",
        "        obs, rewards, done, info = env.step(act)\n",
        "        \n",
        "        # save action, reward\n",
        "        batch_acts.append(act)\n",
        "        ep_rews.append(rewards)\n",
        "        \n",
        "        if done:\n",
        "            # Record info, as episode is complete\n",
        "            ep_ret = sum(ep_rews)\n",
        "            ep_len = len(ep_rews)\n",
        "            \n",
        "            batch_rews.append(ep_ret)\n",
        "            batch_len.append(ep_len)\n",
        "            \n",
        "            batch_weights += [ep_ret] * ep_len\n",
        "            \n",
        "            # Reset the environment\n",
        "            obs, done, ep_rews = env.reset(), False, []\n",
        "            \n",
        "            rendered_once_in_epoch = True\n",
        "            \n",
        "            if batch_size < len(batch_obs):\n",
        "                break\n",
        "                \n",
        "    batch_loss, _ = sess.run([loss, train_op], feed_dict={obs_ph: np.array(batch_obs),\n",
        "                                                              act_ph: np.array(batch_acts),\n",
        "                                                              weights_ph: np.array(batch_weights)})\n",
        "        \n",
        "        \n",
        "    return batch_loss, batch_rews, batch_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGMf9JlpMNyZ",
        "colab_type": "code",
        "outputId": "7f5e9656-cdb0-4bfe-f647-42ac6fb62e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
        "    print ('Epoch: {:.3f} Loss: {:.3f} Return: {:.3f} ep_len: {:.3f}'\n",
        "           .format(epoch+1, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1.000 Loss: 24.082 Return: 26.649 ep_len: 26.649\n",
            "Epoch: 2.000 Loss: 24.285 Return: 28.441 ep_len: 28.441\n",
            "Epoch: 3.000 Loss: 28.568 Return: 32.987 ep_len: 32.987\n",
            "Epoch: 4.000 Loss: 30.247 Return: 35.203 ep_len: 35.203\n",
            "Epoch: 5.000 Loss: 32.122 Return: 40.715 ep_len: 40.715\n",
            "Epoch: 6.000 Loss: 35.210 Return: 44.202 ep_len: 44.202\n",
            "Epoch: 7.000 Loss: 36.932 Return: 48.317 ep_len: 48.317\n",
            "Epoch: 8.000 Loss: 40.528 Return: 50.970 ep_len: 50.970\n",
            "Epoch: 9.000 Loss: 38.384 Return: 53.287 ep_len: 53.287\n",
            "Epoch: 10.000 Loss: 38.973 Return: 53.287 ep_len: 53.287\n",
            "Epoch: 11.000 Loss: 44.026 Return: 61.914 ep_len: 61.914\n",
            "Epoch: 12.000 Loss: 45.591 Return: 62.543 ep_len: 62.543\n",
            "Epoch: 13.000 Loss: 46.638 Return: 69.192 ep_len: 69.192\n",
            "Epoch: 14.000 Loss: 54.469 Return: 76.121 ep_len: 76.121\n",
            "Epoch: 15.000 Loss: 53.321 Return: 76.182 ep_len: 76.182\n",
            "Epoch: 16.000 Loss: 55.920 Return: 76.000 ep_len: 76.000\n",
            "Epoch: 17.000 Loss: 61.135 Return: 85.627 ep_len: 85.627\n",
            "Epoch: 18.000 Loss: 60.521 Return: 88.298 ep_len: 88.298\n",
            "Epoch: 19.000 Loss: 74.435 Return: 107.574 ep_len: 107.574\n",
            "Epoch: 20.000 Loss: 78.541 Return: 114.091 ep_len: 114.091\n",
            "Epoch: 21.000 Loss: 80.942 Return: 131.308 ep_len: 131.308\n",
            "Epoch: 22.000 Loss: 77.807 Return: 116.523 ep_len: 116.523\n",
            "Epoch: 23.000 Loss: 83.605 Return: 131.789 ep_len: 131.789\n",
            "Epoch: 24.000 Loss: 84.607 Return: 138.973 ep_len: 138.973\n",
            "Epoch: 25.000 Loss: 79.274 Return: 123.390 ep_len: 123.390\n",
            "Epoch: 26.000 Loss: 76.397 Return: 123.805 ep_len: 123.805\n",
            "Epoch: 27.000 Loss: 84.773 Return: 133.789 ep_len: 133.789\n",
            "Epoch: 28.000 Loss: 85.987 Return: 134.053 ep_len: 134.053\n",
            "Epoch: 29.000 Loss: 84.268 Return: 129.949 ep_len: 129.949\n",
            "Epoch: 30.000 Loss: 85.829 Return: 135.730 ep_len: 135.730\n",
            "Epoch: 31.000 Loss: 84.755 Return: 138.486 ep_len: 138.486\n",
            "Epoch: 32.000 Loss: 83.371 Return: 132.077 ep_len: 132.077\n",
            "Epoch: 33.000 Loss: 93.952 Return: 154.030 ep_len: 154.030\n",
            "Epoch: 34.000 Loss: 91.733 Return: 147.206 ep_len: 147.206\n",
            "Epoch: 35.000 Loss: 99.097 Return: 167.097 ep_len: 167.097\n",
            "Epoch: 36.000 Loss: 98.725 Return: 166.355 ep_len: 166.355\n",
            "Epoch: 37.000 Loss: 103.311 Return: 176.483 ep_len: 176.483\n",
            "Epoch: 38.000 Loss: 101.345 Return: 165.645 ep_len: 165.645\n",
            "Epoch: 39.000 Loss: 105.146 Return: 177.793 ep_len: 177.793\n",
            "Epoch: 40.000 Loss: 103.690 Return: 176.276 ep_len: 176.276\n",
            "Epoch: 41.000 Loss: 108.041 Return: 182.571 ep_len: 182.571\n",
            "Epoch: 42.000 Loss: 108.131 Return: 189.074 ep_len: 189.074\n",
            "Epoch: 43.000 Loss: 109.167 Return: 188.222 ep_len: 188.222\n",
            "Epoch: 44.000 Loss: 110.307 Return: 196.769 ep_len: 196.769\n",
            "Epoch: 45.000 Loss: 110.184 Return: 190.222 ep_len: 190.222\n",
            "Epoch: 46.000 Loss: 110.235 Return: 197.308 ep_len: 197.308\n",
            "Epoch: 47.000 Loss: 110.812 Return: 198.308 ep_len: 198.308\n",
            "Epoch: 48.000 Loss: 111.371 Return: 199.423 ep_len: 199.423\n",
            "Epoch: 49.000 Loss: 111.377 Return: 200.000 ep_len: 200.000\n",
            "Epoch: 50.000 Loss: 110.583 Return: 197.000 ep_len: 197.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T7PFOoR1Kt8d",
        "colab_type": "code",
        "outputId": "12d64c84-e958-459a-c4e6-887d7e08969f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "# TensorBoard Setup\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('tensorboard --logdir=./tboard/FrozenLake-v0/ &')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-01 19:11:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.232.181.106, 34.226.180.131, 34.232.40.183, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.232.181.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  96%[==================> ]   4.92M  12.2MB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  10.6MB/s    in 0.5s    \n",
            "\n",
            "2018-12-01 19:11:33 (10.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://d2cfdd99.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NYW-0FBOLtja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "for _ in range(1000):\n",
        "    env.step(env.action_space.sample())\n",
        "    show_state(env)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}