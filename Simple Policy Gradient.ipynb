{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Policy Gradient.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "N6DmPO15CELr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple Policy Gradient\n",
        "\n",
        "This notebook contains the implementation of the Simple Policy Gradient Algorithm using TensorFlow.\n",
        "<br/>\n",
        "This notebook is created while going through the official Spinning up in Deep RL Docs."
      ]
    },
    {
      "metadata": {
        "id": "wr_BaDfxCwqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "444d8755-0b9a-4eeb-9dd8-1017601a1385"
      },
      "cell_type": "code",
      "source": [
        "# Required modules\n",
        "!pip install gym\n",
        "!apt-get install python-opengl\n",
        "!pip install pyglet==1.2.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.10.9)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (2.18.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.1.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.4)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.14.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym) (2018.10.15)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Requirement already satisfied: pyglet==1.2.4 in /usr/local/lib/python3.6/dist-packages (1.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SZhpqk-EN2oR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import required modules\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_util\n",
        "from tensorflow.python.platform import gfile\n",
        "import gym\n",
        "from gym.spaces import Discrete, Box\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smhZs1BLOBkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "env_name = 'CartPole-v0'\n",
        "render = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l01SIfVNOO3c",
        "colab_type": "code",
        "outputId": "dcabfc23-7212-4ee2-b67b-c0e2ff507bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the env\n",
        "env = gym.make('CartPole-v0')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
            "  result = entry_point.load(False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zh-CKSfDOUYC",
        "colab_type": "code",
        "outputId": "84b53da7-2d91-4f04-9974-80cc7fde7356",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the action space size and observation space size\n",
        "act_size = env.action_space.n\n",
        "obs_size = env.observation_space.shape[0]\n",
        "\n",
        "print ('Action Space Size: {}'.format(act_size),\n",
        "       '\\nObservation Space Size: {}'.format(obs_size))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Space Size: 2 \n",
            "Observation Space Size: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rxr8GqXeRR8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network Hyperparameters\n",
        "layers = 2\n",
        "hneurons = [32, act_size]\n",
        "epochs = 50\n",
        "batch_size = 5000\n",
        "lr = 1e-2\n",
        "hid_act = tf.tanh\n",
        "out_act = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzCocISRRUSZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build the network\n",
        "obs_ph = tf.placeholder(shape=(None, obs_size), dtype=tf.float32, name='input')\n",
        "\n",
        "a1 = tf.layers.dense(obs_ph, units=hneurons[0], activation=hid_act)\n",
        "logits = tf.layers.dense(a1, units=hneurons[1], activation=None)\n",
        "\n",
        "# Select the action\n",
        "actions = tf.squeeze(tf.multinomial(logits=logits, num_samples=1), axis=1, name='output')\n",
        "\n",
        "# Loss function whose gradient is the policy gradient\n",
        "weights_ph = tf.placeholder(shape=(None,), dtype=tf.float32)\n",
        "act_ph = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
        "action_masks = tf.one_hot(act_ph, act_size)\n",
        "log_probs = tf.reduce_sum(action_masks * tf.nn.log_softmax(logits), axis=1)\n",
        "loss = -tf.reduce_mean(weights_ph * log_probs)\n",
        "\n",
        "# Make the train op\n",
        "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pz-PkV1QNuz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgQJaVxnlYyv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_state(env):\n",
        "    plt.figure(3)\n",
        "    plt.clf()\n",
        "    a = env.render(mode='rgb_array')\n",
        "    print (type(a))\n",
        "    print (a)\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    display.display(plt.gcf())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cqq2GQRKL3HC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_one_epoch():\n",
        "    # Declaring variables to store epoch details\n",
        "    batch_acts = []\n",
        "    batch_len = []\n",
        "    batch_weights = []\n",
        "    batch_rews = []\n",
        "    batch_obs = []\n",
        "    \n",
        "    # Reset env\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    ep_rews = []\n",
        "    rendered_once_in_epoch = False\n",
        "    \n",
        "    while True:\n",
        "        \n",
        "        if not rendered_once_in_epoch:\n",
        "            # For notebooks on server (like Colab)\n",
        "            #show_state(env)\n",
        "            # For notebooks on local machines\n",
        "            #env.render()\n",
        "            pass\n",
        "            \n",
        "        batch_obs.append(obs)\n",
        "        \n",
        "        act = sess.run([actions], feed_dict={obs_ph: obs.reshape(1 ,-1)})[0][0]\n",
        "        \n",
        "        # Take the action\n",
        "        obs, rewards, done, info = env.step(act)\n",
        "        \n",
        "        # save action, reward\n",
        "        batch_acts.append(act)\n",
        "        ep_rews.append(rewards)\n",
        "        \n",
        "        if done:\n",
        "            # Record info, as episode is complete\n",
        "            ep_ret = sum(ep_rews)\n",
        "            ep_len = len(ep_rews)\n",
        "            \n",
        "            batch_rews.append(ep_ret)\n",
        "            batch_len.append(ep_len)\n",
        "            \n",
        "            batch_weights += [ep_ret] * ep_len\n",
        "            \n",
        "            # Reset the environment\n",
        "            obs, done, ep_rews = env.reset(), False, []\n",
        "            \n",
        "            rendered_once_in_epoch = True\n",
        "            \n",
        "            if batch_size < len(batch_obs):\n",
        "                break\n",
        "                \n",
        "    batch_loss, _ = sess.run([loss, train_op], feed_dict={obs_ph: np.array(batch_obs),\n",
        "                                                              act_ph: np.array(batch_acts),\n",
        "                                                              weights_ph: np.array(batch_weights)})\n",
        "        \n",
        "        \n",
        "    return batch_loss, batch_rews, batch_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKBRIwRckTcL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Loop Parameters\n",
        "ckpt_interval = 5\n",
        "save_path = './ckpt_path/'\n",
        "restore = False\n",
        "ckpt_num = 45"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ANJA4dsntcOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving the weights along with the graph\n",
        "def save_graph(sess, graph, graph_name):\n",
        "    output_graph_def = graph_util.convert_variables_to_constants(\n",
        "                        sess, graph.as_graph_def(), ['output'])\n",
        "    with gfile.FastGFile(graph_name, 'wb') as f:\n",
        "        f.write(output_graph_def.SerializeToString())\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGMf9JlpMNyZ",
        "colab_type": "code",
        "outputId": "df0df6f5-896e-45cd-bd06-662b934d775e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1649
        }
      },
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "if restore and ckpt_num != None:\n",
        "    saver.restore(sess, save_path + 'spg_ckpt{}.ckpt'.format(ckpt_num))\n",
        "    print ('[INFO]Model Restored!!')\n",
        "    \n",
        "for epoch in range(epochs):\n",
        "    batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
        "    print ('Epoch: {:.3f} Loss: {:.3f} Return: {:.3f} ep_len: {:.3f}'\n",
        "           .format(epoch+1, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
        "    \n",
        "    if (epoch+1) % ckpt_interval == 0:\n",
        "        print ('[INFO]Saving Checkpoint...')\n",
        "        curr_save_path = saver.save(sess, save_path + 'spg_ckpt{}.ckpt'.format(epoch+1))\n",
        "        print ('[INFO]Session saved Successfully!!')\n",
        "        print ('[INFO]Checkpoint saved at: {}'.format(curr_save_path))\n",
        "        print ('*************************************************')\n",
        "\n",
        "        \n",
        "sess.close()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1.000 Loss: 30.518 Return: 34.384 ep_len: 34.384\n",
            "Epoch: 2.000 Loss: 35.005 Return: 39.786 ep_len: 39.786\n",
            "Epoch: 3.000 Loss: 33.453 Return: 41.372 ep_len: 41.372\n",
            "Epoch: 4.000 Loss: 36.811 Return: 47.047 ep_len: 47.047\n",
            "Epoch: 5.000 Loss: 36.649 Return: 47.255 ep_len: 47.255\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt5.ckpt\n",
            "*************************************************\n",
            "Epoch: 6.000 Loss: 35.193 Return: 49.634 ep_len: 49.634\n",
            "Epoch: 7.000 Loss: 41.239 Return: 57.159 ep_len: 57.159\n",
            "Epoch: 8.000 Loss: 41.997 Return: 58.805 ep_len: 58.805\n",
            "Epoch: 9.000 Loss: 40.687 Return: 60.554 ep_len: 60.554\n",
            "Epoch: 10.000 Loss: 46.847 Return: 65.013 ep_len: 65.013\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt10.ckpt\n",
            "*************************************************\n",
            "Epoch: 11.000 Loss: 45.727 Return: 67.373 ep_len: 67.373\n",
            "Epoch: 12.000 Loss: 46.163 Return: 68.176 ep_len: 68.176\n",
            "Epoch: 13.000 Loss: 46.644 Return: 70.986 ep_len: 70.986\n",
            "Epoch: 14.000 Loss: 48.347 Return: 72.971 ep_len: 72.971\n",
            "Epoch: 15.000 Loss: 44.916 Return: 70.859 ep_len: 70.859\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt15.ckpt\n",
            "*************************************************\n",
            "Epoch: 16.000 Loss: 49.606 Return: 78.625 ep_len: 78.625\n",
            "Epoch: 17.000 Loss: 52.622 Return: 83.295 ep_len: 83.295\n",
            "Epoch: 18.000 Loss: 54.513 Return: 86.655 ep_len: 86.655\n",
            "Epoch: 19.000 Loss: 63.635 Return: 98.667 ep_len: 98.667\n",
            "Epoch: 20.000 Loss: 61.952 Return: 96.673 ep_len: 96.673\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt20.ckpt\n",
            "*************************************************\n",
            "Epoch: 21.000 Loss: 66.223 Return: 105.184 ep_len: 105.184\n",
            "Epoch: 22.000 Loss: 74.331 Return: 116.605 ep_len: 116.605\n",
            "Epoch: 23.000 Loss: 92.553 Return: 154.000 ep_len: 154.000\n",
            "Epoch: 24.000 Loss: 98.307 Return: 166.677 ep_len: 166.677\n",
            "Epoch: 25.000 Loss: 100.738 Return: 173.267 ep_len: 173.267\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt25.ckpt\n",
            "*************************************************\n",
            "Epoch: 26.000 Loss: 100.692 Return: 175.103 ep_len: 175.103\n",
            "Epoch: 27.000 Loss: 101.487 Return: 175.517 ep_len: 175.517\n",
            "Epoch: 28.000 Loss: 98.295 Return: 170.533 ep_len: 170.533\n",
            "Epoch: 29.000 Loss: 103.051 Return: 181.964 ep_len: 181.964\n",
            "Epoch: 30.000 Loss: 97.104 Return: 167.233 ep_len: 167.233\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt30.ckpt\n",
            "*************************************************\n",
            "Epoch: 31.000 Loss: 103.503 Return: 183.893 ep_len: 183.893\n",
            "Epoch: 32.000 Loss: 96.744 Return: 167.967 ep_len: 167.967\n",
            "Epoch: 33.000 Loss: 101.932 Return: 179.786 ep_len: 179.786\n",
            "Epoch: 34.000 Loss: 105.094 Return: 187.037 ep_len: 187.037\n",
            "Epoch: 35.000 Loss: 104.658 Return: 189.407 ep_len: 189.407\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt35.ckpt\n",
            "*************************************************\n",
            "Epoch: 36.000 Loss: 107.406 Return: 190.296 ep_len: 190.296\n",
            "Epoch: 37.000 Loss: 108.210 Return: 194.000 ep_len: 194.000\n",
            "Epoch: 38.000 Loss: 110.185 Return: 199.538 ep_len: 199.538\n",
            "Epoch: 39.000 Loss: 110.261 Return: 198.269 ep_len: 198.269\n",
            "Epoch: 40.000 Loss: 110.595 Return: 200.000 ep_len: 200.000\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt40.ckpt\n",
            "*************************************************\n",
            "Epoch: 41.000 Loss: 106.542 Return: 187.370 ep_len: 187.370\n",
            "Epoch: 42.000 Loss: 109.269 Return: 195.000 ep_len: 195.000\n",
            "Epoch: 43.000 Loss: 107.654 Return: 195.577 ep_len: 195.577\n",
            "Epoch: 44.000 Loss: 109.251 Return: 200.000 ep_len: 200.000\n",
            "Epoch: 45.000 Loss: 107.230 Return: 192.923 ep_len: 192.923\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt45.ckpt\n",
            "*************************************************\n",
            "Epoch: 46.000 Loss: 109.959 Return: 200.000 ep_len: 200.000\n",
            "Epoch: 47.000 Loss: 108.971 Return: 200.000 ep_len: 200.000\n",
            "Epoch: 48.000 Loss: 106.956 Return: 193.154 ep_len: 193.154\n",
            "Epoch: 49.000 Loss: 109.049 Return: 200.000 ep_len: 200.000\n",
            "Epoch: 50.000 Loss: 109.093 Return: 197.731 ep_len: 197.731\n",
            "[INFO]Saving Checkpoint...\n",
            "[INFO]Session saved Successfully!!\n",
            "[INFO]Checkpoint saved at: ./ckpt_path/spg_ckpt50.ckpt\n",
            "*************************************************\n",
            "[INFO]Saving the graph and weights...\n",
            "INFO:tensorflow:Froze 4 variables.\n",
            "INFO:tensorflow:Converted 4 variables to const ops.\n",
            "[INFO]Saved Successfully!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bx8FnKJEl5jf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "14a72db6-6be2-48be-8665-b33e8cd787cf"
      },
      "cell_type": "code",
      "source": [
        "# Download checkpoints\n",
        "dwnld_ckpt = 50\n",
        "for file_ending in ['meta', 'index', 'data-00000-of-00001']:\n",
        "    files.download('./ckpt_path/spg_ckpt{}.ckpt.{}'.format(dwnld_ckpt, file_ending))\n",
        "    print ('[INFO]Download popup for ckpt file with .{} ending sent successfully!!'\n",
        "           .format(file_ending))\n",
        "print ('[INFO]All download notifications for the ckpt {} file sent successfully!!'.format(dwnld_ckpt))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]Download popup for ckpt file with .meta ending sent successfully!!\n",
            "[INFO]Download popup for ckpt file with .index ending sent successfully!!\n",
            "[INFO]Download popup for ckpt file with .data-00000-of-00001 ending sent successfully!!\n",
            "All download notifications for the ckpt 50 file sent successfully!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A4eqbDB0MUBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save the weights and graph\n",
        "if True:\n",
        "    print ('[INFO]Saving the graph and weights...')\n",
        "    save_graph(sess, tf.get_default_graph(), env_name + '_graph.pb')\n",
        "    print ('[INFO]Saved Successfully!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8tnkVtkL7KU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the graph\n",
        "model_file = './CartPole-v0_graph.pb'\n",
        "\n",
        "def load_graph(model_file):\n",
        "    print ('[INFO]Loading Model...')\n",
        "    graph = tf.Graph()\n",
        "    graph_def = tf.GraphDef()\n",
        "    \n",
        "    print ('[INFO]Reading model file...')\n",
        "    with open(model_file, 'rb') as f:\n",
        "        graph_def.ParseFromString(f.read())\n",
        "\n",
        "    with graph.as_default():\n",
        "        tf.import_graph_def(graph_def)\n",
        "    \n",
        "    print ('[INFO]Model Loaded Successfully!!')\n",
        "    return graph\n",
        "\n",
        "graph = load_graph(model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aVfyM9s7NGkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99db5720-d089-4fae-bf87-de275a836c05"
      },
      "cell_type": "code",
      "source": [
        "# Test the network\n",
        "\n",
        "input_layer = 'import/input'\n",
        "output_layer = 'import/output'\n",
        "\n",
        "input_op = graph.get_operation_by_name(input_layer)\n",
        "output_op = graph.get_operation_by_name(output_layer)\n",
        "\n",
        "\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "    \n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    ep_rews = 0\n",
        "    \n",
        "    while not done:\n",
        "        act = sess.run([output_op.outputs[0]], feed_dict={input_op.outputs[0]: obs.reshape(1, -1)})\n",
        "        \n",
        "        obs, rewards, done, info = env.step(act[0][0])\n",
        "        \n",
        "        ep_rews += rewards\n",
        "        \n",
        "    print ('Test Episode Rewards: {}'.format(ep_rews))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Episode Rewards: 200.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T7PFOoR1Kt8d",
        "colab_type": "code",
        "outputId": "12d64c84-e958-459a-c4e6-887d7e08969f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "cell_type": "code",
      "source": [
        "# TensorBoard Setup\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('tensorboard --logdir=./tboard/FrozenLake-v0/ &')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-01 19:11:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.232.181.106, 34.226.180.131, 34.232.40.183, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.232.181.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  96%[==================> ]   4.92M  12.2MB/s               \rngrok-stable-linux- 100%[===================>]   5.11M  10.6MB/s    in 0.5s    \n",
            "\n",
            "2018-12-01 19:11:33 (10.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://d2cfdd99.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}